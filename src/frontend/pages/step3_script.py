"""
Step 3: ‡∏ö‡∏ó‡∏û‡∏π‡∏î (Script & Audio)
Voice personality, script text, AI Studio integration, audio upload and segmentation
"""
import streamlit as st
import os
import re
import unicodedata
import logging
from pathlib import Path

logger = logging.getLogger("vdo_content.step3")




# Imports
from src.core.models import AudioSegment
from src.shared.project_manager import save_project
from src.frontend.utils import show_back_button, auto_save_project, show_step_guard
from src.config.constants import (
    STEP_CONTENT, STEP_VIDEO_PROMPT, STEP_SCRIPT,
    VOICE_PERSONALITIES, DATA_DIR,
    CONTENT_CATEGORIES, VIDEO_FORMATS, PLATFORMS
)


def extract_voiceover_text(raw_script: str) -> str:
    """Extract only spoken narration, removing stage directions, scene markers, and non-spoken elements.
    
    This is the single source of truth for cleaning AI-generated scripts.
    It strips everything that isn't actual spoken narration text.
    """
    if not raw_script:
        return ""
    lines = raw_script.split("\n")
    spoken = []
    for line in lines:
        stripped = line.strip()
        if not stripped:
            continue
        # Skip lines that are entirely in parentheses (stage directions)
        # e.g. (‡∏â‡∏≤‡∏Å‡πÄ‡∏õ‡∏¥‡∏î‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡∏ú‡∏π‡πâ‡∏´‡∏ç‡∏¥‡∏á...), (‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏®‡∏™‡∏µ‡∏û‡∏≤‡∏™‡πÄ‡∏ó‡∏•‡∏≠‡πà‡∏≠‡∏ô‡πÜ...)
        if stripped.startswith("(") and stripped.endswith(")"):
            continue
        # Skip Thai visual/scene directions that START with ( + Thai direction keyword
        # e.g. (‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡∏¥‡∏î‡∏ï‡∏±‡∏ß: ...), (‡∏â‡∏≤‡∏Å‡πÄ‡∏õ‡∏¥‡∏î‡∏î‡πâ‡∏ß‡∏¢...), (‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£‡∏¢‡∏∑‡∏ô...), (‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏®...)
        # These may not end with ) if the AI truncates or wraps them
        if re.match(r'^\((?:‡∏†‡∏≤‡∏û|‡∏â‡∏≤‡∏Å|‡∏ï‡∏±‡∏ß‡∏•‡∏∞‡∏Ñ‡∏£|‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏®|‡πÄ‡∏™‡∏µ‡∏¢‡∏á|‡πÅ‡∏™‡∏á|‡∏Å‡∏•‡πâ‡∏≠‡∏á|‡∏°‡∏∏‡∏°‡∏Å‡∏•‡πâ‡∏≠‡∏á|‡∏ã‡∏π‡∏°|‡πÅ‡∏û‡∏ô|‡∏ó‡∏±‡∏ô‡πÉ‡∏î‡∏ô‡∏±‡πâ‡∏ô|‡∏™‡∏•‡∏¥‡∏ï|‡∏Ñ‡∏±‡∏ó|‡πÇ‡∏Ñ‡∏•‡∏™‡∏≠‡∏±‡∏û|‡πÑ‡∏ß‡∏î‡πå‡∏ä‡πá‡∏≠‡∏ï)', stripped):
            continue
        # Skip lines in square brackets [Scene 1], [‡∏â‡∏≤‡∏Å 1] etc.
        if stripped.startswith("[") and stripped.endswith("]"):
            continue
        # Skip scene/marker headers: "Scene 1:", "‡∏â‡∏≤‡∏Å‡∏ó‡∏µ‡πà 1:", "‡∏â‡∏≤‡∏Å 1:"
        if re.match(r'^(scene|‡∏â‡∏≤‡∏Å|‡∏â‡∏≤‡∏Å‡∏ó‡∏µ‡πà)\s*\d+', stripped, re.IGNORECASE):
            continue
        # Skip separator lines (---, ===, ***)
        if re.match(r'^[-=*]{3,}$', stripped):
            continue
        # Skip markdown bold headers like **‡∏â‡∏≤‡∏Å‡∏ó‡∏µ‡πà 1:** or **‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á**
        if re.match(r'^\*\*[^*]+\*\*:?\s*$', stripped):
            continue
        # Skip emoji-prefixed headers like üé¨ ‡∏â‡∏≤‡∏Å‡πÄ‡∏õ‡∏¥‡∏î, üìå ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏
        if re.match(r'^[\U0001F300-\U0001FAFF„ÅÅ-„É∂]', stripped):
            continue
        # Skip numbered outline markers like "1.", "1)", "‡∏Ç‡πâ‡∏≠ 1."
        if re.match(r'^(\d+[.):]|‡∏Ç‡πâ‡∏≠\s*\d+)', stripped):
            continue
        # Skip lines that are entirely stage direction keywords
        direction_keywords = (
            '‡∏â‡∏≤‡∏Å‡πÄ‡∏õ‡∏¥‡∏î', '‡∏â‡∏≤‡∏Å‡∏õ‡∏¥‡∏î', '‡∏ï‡∏±‡∏î‡∏â‡∏≤‡∏Å', '‡πÄ‡∏ü‡∏î‡∏≠‡∏¥‡∏ô', '‡πÄ‡∏ü‡∏î‡πÄ‡∏≠‡∏≤‡∏ó‡πå',
            'fade in', 'fade out', 'cut to', 'dissolve',
        )
        if stripped.lower() in direction_keywords:
            continue
        # Remove inline parenthetical directions from the line
        cleaned = re.sub(r'\([^)]*\)', '', stripped).strip()
        # Remove inline markdown bold markers
        cleaned = re.sub(r'\*\*([^*]+)\*\*', r'\1', cleaned).strip()
        if cleaned:
            spoken.append(cleaned)
    return "\n".join(spoken)

# Try import DB functions for enriched context
try:
    from src.core.database import get_content_goals, get_target_audiences, get_video_profile
    DB_AVAILABLE = True
except ImportError:
    DB_AVAILABLE = False



# Try import AI generators
try:
    from src.core.script_generator import ScriptGenerator
    SCRIPT_GEN_AVAILABLE = True
except ImportError:
    SCRIPT_GEN_AVAILABLE = False

try:
    from src.core.aistudio_generator import generate_ai_studio_output
    AISTUDIO_AVAILABLE = True
except ImportError:
    AISTUDIO_AVAILABLE = False


def _show_step2_context(project):
    """Display Step 2 data summary at the top of Step 3"""
    has_data = any([
        project.content_description or project.topic,
        project.content_goal,
        project.target_audience,
        getattr(project, 'content_category', ''),
        getattr(project, 'platforms', []),
        getattr(project, 'video_format', ''),
    ])
    
    if not has_data:
        st.info("üí° ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Step 2 ‚Äî ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ó‡∏ô‡∏ï‡πå‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ó‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô")
        return
    
    with st.expander("üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Step 2 (‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ó‡∏ô‡∏ï‡πå)", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            desc = project.content_description or project.topic or "‚Äì"
            st.markdown(f"**üìå ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠:** {desc[:100]}{'...' if len(desc) > 100 else ''}")
            st.markdown(f"**üéØ ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢:** {project.content_goal or '‚Äì'}")
            st.markdown(f"**üë• ‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢:** {project.target_audience or '‚Äì'}")
        with col2:
            category = getattr(project, 'content_category', '')
            category_name = dict(CONTENT_CATEGORIES).get(category, category) if category else '‚Äì'
            st.markdown(f"**üìÇ ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà:** {category_name}")
            
            video_format = getattr(project, 'video_format', '')
            format_name = dict(VIDEO_FORMATS).get(video_format, video_format) if video_format else '‚Äì'
            st.markdown(f"**üìπ ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö:** {format_name}")
            
            platforms = getattr(project, 'platforms', [])
            if platforms:
                platform_names = [dict(PLATFORMS).get(p, p) for p in platforms]
                st.markdown(f"**üåê ‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°:** {', '.join(platform_names)}")
            else:
                st.markdown("**üåê ‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°:** ‚Äì")
        
        st.markdown(f"**‚è±Ô∏è ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢:** {project.target_duration} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
        
        if project.generated_content:
            st.markdown("---")
            st.markdown("**ü§ñ ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà AI ‡∏™‡∏£‡πâ‡∏≤‡∏á (Step 2):**")
            st.markdown(project.generated_content)


def _build_script_context(project) -> str:
    """Build enriched topic context from Step 2 data for script generation"""
    parts = []
    
    # Base topic/description
    base_topic = project.content_description or project.topic or ""
    parts.append(f"üìå ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {base_topic}")
    
    # Video Profile (enriched from DB)
    profile_id = getattr(project, 'video_profile_id', None)
    if DB_AVAILABLE and profile_id:
        try:
            profile_data = get_video_profile(profile_id)
            if profile_data:
                parts.append(f"üé¨ Profile: {profile_data.get('name_th', '')} ({profile_data.get('name_en', '')})")
        except Exception:
            pass
    
    # Content Goal (enriched from DB)
    goal_text = project.content_goal or ""
    goal_hint = ""
    if DB_AVAILABLE and getattr(project, 'content_goal_id', None):
        try:
            goals = get_content_goals()
            goal_data = next((g for g in goals if g["id"] == project.content_goal_id), None)
            if goal_data:
                goal_text = f"{goal_data['name_th']} ‚Äî {goal_data.get('description', '')}"
                goal_hint = goal_data.get("prompt_hint", "")
        except Exception:
            pass
    if goal_text:
        parts.append(f"üéØ ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: {goal_text}")
    
    # Target Audience (enriched from DB)
    audience_text = project.target_audience or ""
    if DB_AVAILABLE and getattr(project, 'target_audience_id', None):
        try:
            audiences = get_target_audiences()
            aud_data = next((a for a in audiences if a["id"] == project.target_audience_id), None)
            if aud_data:
                audience_text = f"{aud_data['name_th']} ({aud_data.get('age_range', '')}) ‚Äî {aud_data.get('description', '')}"
        except Exception:
            pass
    if audience_text:
        parts.append(f"üë• ‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: {audience_text}")
    
    # Category
    category = getattr(project, 'content_category', '')
    if category:
        category_name = dict(CONTENT_CATEGORIES).get(category, category)
        parts.append(f"üìÇ ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà: {category_name}")
    
    # Platforms
    platforms = getattr(project, 'platforms', [])
    if platforms:
        platform_names = [dict(PLATFORMS).get(p, p) for p in platforms]
        parts.append(f"üåê ‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°: {', '.join(platform_names)}")
    
    # Video Format
    video_format = getattr(project, 'video_format', '')
    if video_format:
        format_name = dict(VIDEO_FORMATS).get(video_format, video_format)
        parts.append(f"üìπ ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: {format_name}")
    
    # Duration
    parts.append(f"‚è±Ô∏è ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: {project.target_duration} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
    
    # Goal-specific prompt hint for LLM
    if goal_hint:
        parts.append(f"\nüí° ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: {goal_hint}")
    
    # Generated content from Step 2 (AI analysis)
    generated = getattr(project, 'generated_content', '')
    if generated:
        parts.append(f"\nüìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤:\n{generated}")
    
    return "\n".join(parts)


def render():
    """Step 3: ‡∏ö‡∏ó‡∏û‡∏π‡∏î"""
    # Back button
    if st.button("‚Üê ‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö: ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ó‡∏ô‡∏ï‡πå"):
        st.session_state.page = STEP_CONTENT
        st.rerun()
    
    st.title("3Ô∏è‚É£ ‡∏ö‡∏ó‡∏û‡∏π‡∏î")
    
    if not show_step_guard(2):
        return
    
    project = st.session_state.current_project
    st.caption(f"üìÅ ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ: **{project.title}**")
    
    # Show Step 2 context summary
    _show_step2_context(project)
    
    st.markdown("---")
    
    # ===== STEP A: VOICE PERSONALITY =====
    st.subheader("üé≠ A. ‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ô‡πâ‡∏≥‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
    
    personality_options = {p[0]: p[1] for p in VOICE_PERSONALITIES}
    # Callback to update style instructions when personality changes
    def _on_personality_change():
        new_personality = st.session_state.step3_personality
        project.voice_personality = new_personality
        
        # Generate new default style based on selection
        p_label = personality_options.get(new_personality, 'Warm & Friendly')
        new_style = f"Tone: {p_label}. Read in a natural, conversational way."
        
        project.style_instructions = new_style
        # Force update the text area widget state
        st.session_state.step3_style = new_style
        st.session_state.current_project = project
        auto_save_project()

    selected_personality = st.selectbox(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ô‡πâ‡∏≥‡πÄ‡∏™‡∏µ‡∏¢‡∏á",
        options=list(personality_options.keys()),
        format_func=lambda x: personality_options.get(x, x),
        index=list(personality_options.keys()).index(project.voice_personality) if project.voice_personality in personality_options else 0,
        key="step3_personality",
        on_change=_on_personality_change
    )
    # Handled in callback: project.voice_personality = selected_personality
    
    st.markdown("---")
    
    # ===== STEP B: SCRIPT =====
    st.subheader("üìù B. ‡∏ö‡∏ó‡∏û‡∏π‡∏î")
    
    # Check if AI just generated a script (stored in separate key before rerun)
    if "_generated_script" in st.session_state and st.session_state._generated_script:
        # Clean the generated script before applying
        clean_generated = extract_voiceover_text(st.session_state._generated_script)
        project.full_script = clean_generated
        # CRITICAL: Also set the widget's own session state key so the text_area
        # picks up the new value on this render cycle (Streamlit widget state fix)
        st.session_state.step3_script = clean_generated
        st.session_state.current_project = project
        del st.session_state._generated_script  # Clear after applying
    
    display_script = extract_voiceover_text(project.full_script) if project.full_script else ""
    
    # Callback to save script immediately on change
    def _on_script_change():
        project.full_script = st.session_state.step3_script
        st.session_state.current_project = project
        auto_save_project()
    
    # Script text area (single source ‚Äî only show actual script, not Step 2 description)
    script_text = st.text_area(
        "‡∏ö‡∏ó‡∏û‡∏π‡∏î (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)",
        value=display_script,
        height=200,
        placeholder="‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° '‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ó‡∏î‡πâ‡∏ß‡∏¢ AI' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ó‡∏û‡∏π‡∏î‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ ‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ö‡∏ó‡πÄ‡∏≠‡∏á...",
        key="step3_script",
        on_change=_on_script_change
    )
    # project.full_script is updated via callback, no need to set it here again
    # But we keep the assignment for immediate local variable usage if needed
    project.full_script = script_text 

    
    if not script_text.strip():
        st.info("üí° ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ö‡∏ó‡∏û‡∏π‡∏î ‚Äî ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° **‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ó‡∏î‡πâ‡∏ß‡∏¢ AI** ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Step 2")
    
    col_info, col_ai = st.columns([2, 1])
    with col_info:
        st.caption(f"üìä {len(script_text)} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ | ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì {len(script_text) // 10:.0f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
    
    # --- Model selector for script generation ---
    AI_SCRIPT_MODELS = {
        "üß† DeepSeek": {
            "provider": "deepseek",
            "api_key_env": "DEEPSEEK_API_KEY",
        },
        "üåô Kimi K2.5": {
            "provider": "kimi",
            "api_key_env": "KIMI_API_KEY",
        },
    }
    
    selected_script_model = st.radio(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å AI Model ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ó",
        list(AI_SCRIPT_MODELS.keys()),
        horizontal=True,
        key="step3_model_select"
    )
    model_cfg = AI_SCRIPT_MODELS[selected_script_model]
    
    with col_ai:
        if st.button("ü§ñ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ó‡∏î‡πâ‡∏ß‡∏¢ AI", use_container_width=True):
            script_api_key = os.getenv(model_cfg["api_key_env"], "")
            if SCRIPT_GEN_AVAILABLE and script_api_key:
                try:
                    with st.spinner(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ó‡∏î‡πâ‡∏ß‡∏¢ {selected_script_model}..."):
                        generator = ScriptGenerator(
                            api_key=script_api_key,
                            provider=model_cfg["provider"],
                        )
                        
                        enriched_topic = _build_script_context(project)
                        
                        script = generator.generate_script(
                            topic=enriched_topic,
                            style=project.voice_personality or "documentary",
                            target_duration=project.target_duration,
                            language="th",
                            story_proposal=getattr(project, 'proposal', None),
                        )
                        # Store in separate key (NOT widget key) to avoid Streamlit error
                        st.session_state._generated_script = extract_voiceover_text(script)
                        st.rerun()
                except Exception as e:
                    st.error(f"‚ùå ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏ó‡∏û‡∏π‡∏î‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
                    st.info("üí° ‡∏•‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö: 1) API Key ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á 2) ‡∏°‡∏µ‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï 3) ‡∏•‡∏≠‡∏á‡∏Å‡∏î‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
            else:
                st.warning(f"‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà {model_cfg['api_key_env']} ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .env")
    
    st.markdown("---")
    
    # ===== STEP C: VOICE GENERATION (AI Studio Helper) =====
    st.subheader("üéôÔ∏è C. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏≤‡∏Å‡∏¢‡πå")
    st.caption("‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ö‡∏ó‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏•‡πâ‡∏ß ‚Üí Copy ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö Google AI Studio")
    
    # Auto-generate style from voice personality (no separate button needed)
    default_style = f"Tone: {personality_options.get(selected_personality, 'Warm & Friendly')}. Read in a natural, conversational way."
    if not project.style_instructions:
        project.style_instructions = default_style
    
    with st.expander("üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI Studio", expanded=False):
        # Style instructions (editable)
        style_box = st.text_area(
            "Style Instructions (‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÑ‡∏î‡πâ)",
            value=project.style_instructions or default_style,
            height=80,
            key="step3_style"
        )
        project.style_instructions = style_box
        
        # Copy sections with reliable copy buttons
        col_copy_style, col_copy_script = st.columns(2)
        with col_copy_style:
            st.markdown("**üé≠ Style Instructions:**")
            st.code(style_box, language=None)
            st.download_button(
                "üíæ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Style",
                data=style_box,
                file_name="style_instructions.txt",
                mime="text/plain",
                key="dl_style",
                use_container_width=True,
            )
        
        # Script preview with copy ‚Äî ONLY spoken narration (strip stage directions)
        with col_copy_script:
            vo_text = extract_voiceover_text(script_text)
            st.markdown("**üìù ‡∏ö‡∏ó‡∏û‡∏π‡∏î (Voiceover):**")
            st.code(vo_text or "(‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ö‡∏ó‡∏û‡∏π‡∏î)", language=None)
            st.download_button(
                "üíæ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ö‡∏ó‡∏û‡∏π‡∏î",
                data=vo_text or "",
                file_name="voiceover_script.txt",
                mime="text/plain",
                key="dl_script",
                use_container_width=True,
            )
        
        st.caption("üí° **‡∏ß‡∏¥‡∏ò‡∏µ Copy:** ‡∏Å‡∏î‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô üìã ‡∏ó‡∏µ‡πà‡∏°‡∏∏‡∏°‡∏Ç‡∏ß‡∏≤‡∏ö‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î")
        
        # Action buttons
        st.markdown("---")
        col_link, col_help = st.columns([1, 1])
        with col_link:
            st.link_button(
                "üåü ‡πÄ‡∏õ‡∏¥‡∏î AI Studio",
                "https://aistudio.google.com/generate-speech",
                type="primary",
                use_container_width=True
            )
        with col_help:
            st.markdown("""**‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ:**
1. Copy **Style** (‡∏ã‡πâ‡∏≤‡∏¢) ‚Üí Paste ‡πÉ‡∏ô AI Studio
2. Copy **Script** (‡∏Ç‡∏ß‡∏≤) ‚Üí Paste ‡πÉ‡∏ô AI Studio
3. ‡∏Å‡∏î **Generate** ‚Üí **Download**
4. ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á""")
    
    st.markdown("---")
    
    # ===== STEP D: AUDIO UPLOAD =====
    st.subheader("üé§ D. ‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏•‡∏¥‡∏õ‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
    
    # Show existing audio if available
    if project.audio_path and os.path.exists(project.audio_path):
        st.success(f"‚úÖ ‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {Path(project.audio_path).name}")
        st.audio(project.audio_path)
        
        if st.button("üóëÔ∏è ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á"):
            project.audio_path = None
            project.audio_segments = []
            st.session_state.current_project = project
            auto_save_project()
            st.session_state.page = STEP_SCRIPT
            st.rerun()
    
    # Upload audio
    uploaded_audio = st.file_uploader(
        "‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á (MP3, WAV, M4A)",
        type=["mp3", "wav", "m4a", "ogg", "flac"],
        key="step3_audio_upload"
    )
    
    if uploaded_audio:
        # Save to project folder
        project_dir = DATA_DIR / project.project_id
        audio_filename = f"audio_{uploaded_audio.name}"
        audio_path = project_dir / audio_filename
        
        # Check if this file is already processed to prevent infinite loop
        # Compare filenames to avoid absolute/relative path mismatch issues
        should_process = True
        if project.audio_path:
            try:
                # Normalize strings to handle Thai characters (NFC)
                current_name = unicodedata.normalize('NFC', Path(project.audio_path).name)
                new_name = unicodedata.normalize('NFC', audio_filename)
                
                # Check 1: Valid previous path and file exists
                if current_name == new_name and os.path.exists(project.audio_path):
                    should_process = False
            except Exception:
                # Fallback to simple comparison if normalization fails
                if Path(project.audio_path).name == audio_filename:
                    should_process = False

        if should_process:
            project_dir.mkdir(parents=True, exist_ok=True)
            
            with open(audio_path, "wb") as f:
                f.write(uploaded_audio.getvalue())
            
            project.audio_path = str(audio_path)
            st.session_state.current_project = project
            auto_save_project()
            
            st.success(f"‚úÖ ‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {uploaded_audio.name}")
            st.rerun()
    
    st.markdown("---")
    
    # ===== AUDIO SEGMENTATION =====
    if project.audio_path and os.path.exists(project.audio_path):
        st.subheader("‚úÇÔ∏è E. ‡∏ã‡∏≠‡∏¢‡∏¢‡πà‡∏≠‡∏¢‡∏Ñ‡∏•‡∏¥‡∏õ‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
        
        # --- Cloud transcription (Groq) ---
        from src.core.cloud_transcriber import CloudTranscriber, GROQ_WHISPER_MODELS
        
        groq_available = CloudTranscriber.is_available()
        
        if not groq_available:
            st.warning(
                "‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ `GROQ_API_KEY`\n\n"
                "1. ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏ü‡∏£‡∏µ‡∏ó‡∏µ‡πà [console.groq.com](https://console.groq.com)\n"
                "2. ‡πÉ‡∏™‡πà key ‡πÉ‡∏ô `.env` ‚Üí `GROQ_API_KEY=gsk_xxxx`\n"
                "3. Restart ‡πÅ‡∏≠‡∏û"
            )
        
        col_cloud_model, col_ai = st.columns(2)
        with col_cloud_model:
            cloud_model = st.selectbox(
                "üß† Cloud Model",
                options=list(GROQ_WHISPER_MODELS.keys()),
                index=0,
                format_func=lambda x: GROQ_WHISPER_MODELS[x]["name"],
                help="whisper-large-v3-turbo ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡πÄ‡∏£‡πá‡∏ß + ‡πÅ‡∏°‡πà‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢"
            )
        with col_ai:
            ai_correct = st.checkbox(
                "‚ú® ‡∏ï‡∏£‡∏ß‡∏à‡∏ó‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢ AI (DeepSeek)",
                value=True,
                help="‡πÉ‡∏ä‡πâ LLM ‡πÅ‡∏Å‡πâ‡∏Ñ‡∏≥‡∏™‡∏∞‡∏Å‡∏î‡∏ú‡∏¥‡∏î‡∏´‡∏•‡∏±‡∏á‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏ö‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‚Üí ‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢"
            )
        
        st.caption(f"{GROQ_WHISPER_MODELS[cloud_model]['desc']}  ‚Ä¢  üí∞ ‡∏ü‡∏£‡∏µ (2000 req/‡∏ß‡∏±‡∏ô)  ‚Ä¢  üß† RAM: 0 GB")
        
        if st.button("üéôÔ∏è ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ã‡∏≠‡∏¢‡∏Ñ‡∏•‡∏¥‡∏õ‡πÄ‡∏™‡∏µ‡∏¢‡∏á", type="primary", use_container_width=True):
            if not groq_available:
                st.error("‚ùå ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ GROQ_API_KEY ‚Äî ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡πÉ‡∏ô .env ‡∏Å‡πà‡∏≠‡∏ô")
            else:
                try:
                    import time
                    from src.core.transcriber import AudioTranscriber
                    
                    # Context prompt for Thai transcription
                    thai_prompt = (
                        "‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏ó‡∏û‡∏π‡∏î‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏£‡∏≤‡∏ß‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö "
                        f"{project.topic or '‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ'} "
                        "‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ó‡∏±‡∏ö‡∏®‡∏±‡∏û‡∏ó‡πå‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≥‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á ‡πÄ‡∏ä‡πà‡∏ô AI, Technology"
                    )
                    
                    with st.spinner(f"‚òÅÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏õ Groq ({GROQ_WHISPER_MODELS[cloud_model]['name']})..."):
                        t0 = time.time()
                        transcriber = CloudTranscriber(model=cloud_model)
                        result = transcriber.transcribe_with_summary(
                            project.audio_path,
                            language="th",
                            initial_prompt=thai_prompt
                        )
                        elapsed = time.time() - t0
                    
                    st.toast(f"‚ö° ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÉ‡∏ô {elapsed:.1f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ!", icon="‚òÅÔ∏è")
                    
                    raw_segments = result["segments"]
                    model_label = f"‚òÅÔ∏è {GROQ_WHISPER_MODELS[cloud_model]['name']}"
                    
                    # LLM Post-Correction (DeepSeek)
                    if ai_correct and raw_segments:
                        deepseek_key = os.environ.get("DEEPSEEK_API_KEY", "")
                        if deepseek_key:
                            with st.spinner("‚ú® ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏ó‡∏≤‡∏ô‡∏Ñ‡∏≥‡∏™‡∏∞‡∏Å‡∏î‡∏î‡πâ‡∏ß‡∏¢ DeepSeek..."):
                                reference = project.full_script or ""
                                raw_segments = AudioTranscriber.correct_with_llm(
                                    segments=raw_segments,
                                    reference_script=reference,
                                    api_key=deepseek_key,
                                    provider="deepseek",
                                )
                            st.toast("‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏ó‡∏≤‡∏ô‡∏Ñ‡∏≥‡∏™‡∏∞‡∏Å‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à!", icon="‚ú®")
                        else:
                            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö DEEPSEEK_API_KEY ‚Äî ‡∏Ç‡πâ‡∏≤‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏ó‡∏≤‡∏ô")
                    
                    # Convert to AudioSegment
                    segments = []
                    for i, seg in enumerate(raw_segments, 1):
                        segments.append(AudioSegment(
                            order=i,
                            start_time=seg.start,
                            end_time=seg.end,
                            duration=round(seg.end - seg.start, 2),
                            text_content=seg.text
                        ))
                    
                    project.audio_segments = segments
                    project.audio_duration = result["total_duration"]
                    project.full_script = result["full_text"]
                    
                    st.session_state.current_project = project
                    auto_save_project()
                    
                    ai_flag = " + AI ‡∏ï‡∏£‡∏ß‡∏à‡∏ó‡∏≤‡∏ô" if ai_correct else ""
                    st.success(f"‚úÖ ‡∏ã‡∏≠‡∏¢‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡πÑ‡∏î‡πâ {len(segments)} ‡∏â‡∏≤‡∏Å (‡∏£‡∏ß‡∏° {result['total_duration']:.1f}s, {model_label}{ai_flag})")
                    st.rerun()
                    
                except Exception as e:
                    logger.error(f"Audio segmentation failed: {e}", exc_info=True)
                    error_msg = str(e)
                    if "GROQ_API_KEY" not in error_msg:
                        st.error(f"‚ùå ‡∏ã‡∏≠‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
                        st.info(
                            "üí° **‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:**\n"
                            "1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö (.mp3, .wav, .m4a)\n"
                            "2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö internet connection\n"
                            "3. ‡∏•‡∏≠‡∏á‡∏Å‡∏î‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á"
                        )
        
        # Display segments
        if project.audio_segments:
            st.markdown("**üìä ‡∏â‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏ã‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß:**")
            
            for i, seg in enumerate(project.audio_segments):
                if seg.duration > 8.0:
                    status = "üî¥"
                elif seg.duration < 7.0:
                    status = "üü°"
                else:
                    status = "üü¢"
                with st.expander(f"{status} ‡∏â‡∏≤‡∏Å {seg.order}: {seg.time_range} ({seg.duration:.1f}s)"):
                    col1, col2 = st.columns([3, 1])
                    
                    with col1:
                        new_text = st.text_area(
                            "‡∏ö‡∏ó‡∏û‡∏π‡∏î",
                            value=seg.text_content,
                            key=f"seg_{i}",
                            height=80
                        )
                        seg.text_content = new_text
                    
                    with col2:
                        st.metric("Duration", f"{seg.duration:.1f}s")
                        if seg.duration > 8.0:
                            st.warning("‚ö†Ô∏è ‡πÄ‡∏Å‡∏¥‡∏ô 8 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ!")
                        elif seg.duration < 7.0:
                            st.info("üí° ‡∏™‡∏±‡πâ‡∏ô‡∏Å‡∏ß‡πà‡∏≤ 7 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
    
    st.markdown("---")
    
    # ===== ACTION BUTTONS =====
    col_save, col_next = st.columns(2)
    
    with col_save:
        if st.button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ö‡∏ó‡∏û‡∏π‡∏î", use_container_width=True):
            project.status = "step3_script"
            project.workflow_step = 2
            st.session_state.current_project = project
            save_project(project)
            st.success("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ö‡∏ó‡∏û‡∏π‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
    
    with col_next:
        if st.button("‚û°Ô∏è ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ: ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt Vdo", type="primary", use_container_width=True):
            project.status = "step4_prompt"
            project.workflow_step = 3
            st.session_state.current_project = project
            save_project(project)
            st.session_state.page = STEP_VIDEO_PROMPT
            st.rerun()
